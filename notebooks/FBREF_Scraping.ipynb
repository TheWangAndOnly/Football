{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a48a0c83",
   "metadata": {},
   "source": [
    "# FBREF by Statsbomb "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d09b17",
   "metadata": {},
   "source": [
    "## Bayern example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "562b6f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from datetime import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a4a1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fbref_player_stats(lst_league_names, lst_seasons):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to scrape player stats from FBref.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    ## Define list of league names\n",
    "    league_names_long = lst_league_names\n",
    "    \n",
    "    \n",
    "    ## Define seasons to scrape\n",
    "    seasons = lst_seasons\n",
    "    \n",
    "    \n",
    "    ## Start timer\n",
    "    tic = datetime.datetime.now()\n",
    "    \n",
    "    \n",
    "    ## Print time scraping started\n",
    "    print(f'Scraping started at: {tic}')\n",
    "    \n",
    "    \n",
    "    ## Scrape information for each player\n",
    "    for season in seasons:\n",
    "\n",
    "        ### Print message\n",
    "        print(f'Scraping started for the {season} season...')\n",
    "\n",
    "        ### Loop through leagues\n",
    "        for league_name_long in league_names_long:\n",
    "            \n",
    "            #### Determine league short name from the league names dictionary\n",
    "            league_name_short = [v for k,v in dict_league_names.items() if k == league_name_long][0]\n",
    "            \n",
    "            #### Save Player URL List (if not already saved)\n",
    "            if not os.path.exists(os.path.join(data_dir_fbref + f'/raw/outfield/{league_name_long}/{season}/fbref_outfield_player_stats_{league_name_long}_{season}_latest.csv')):\n",
    "\n",
    "                ##### Scraping\n",
    "\n",
    "                ##### Print statement\n",
    "                print(f'Scraping started for player stats data for {league_name_long} league for the {season} season...')\n",
    "\n",
    "                ##### Standard stats\n",
    "                print(f'Scraping Standard stats...')\n",
    "                url_std_stats = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fstats%2Fplayers%2F{season}-{league_name_long}&div=div_stats_standard'\n",
    "                df_std_stats = pd.read_html(url_std_stats, header=1)[0]\n",
    "\n",
    "                ##### Goalkeeper stats\n",
    "                #print(f'Scraping Goalkeeper stats...')\n",
    "                #url_keepers = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fkeepers%2Fplayers%2F{season}-{league_name_long}&div=div_stats_keeper'\n",
    "                #df_keepers = pd.read_html(url_keepers, header=1)[0]\n",
    "\n",
    "                ##### Advanced Goalkeeper stats\n",
    "                #print(f'Scraping Advanced Goalkeeper stats...')\n",
    "                #url_keepers_adv = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fkeepersadv%2Fplayers%2F{season}-{league_name_long}&div=div_stats_keeper_adv'\n",
    "                #df_keepers_adv = pd.read_html(url_keepers_adv, header=1)[0]\n",
    "\n",
    "                ##### Shooting stats\n",
    "                print(f'Scraping Shooting stats...')\n",
    "                url_shooting = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fshooting%2Fplayers%2F{season}-{league_name_long}&div=div_stats_shooting'\n",
    "                df_shooting = pd.read_html(url_shooting, header=1)[0]\n",
    "\n",
    "                ##### Passing stats\n",
    "                print(f'Scraping Passing stats...')\n",
    "                url_passing = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fpassing%2Fplayers%2F{season}-{league_name_long}&div=div_stats_passing'\n",
    "                df_passing = pd.read_html(url_passing, header=1)[0]\n",
    "\n",
    "                ##### Pass Types stats\n",
    "                print(f'Scraping Pass Types stats...')\n",
    "                url_passing_types = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fpassing_types%2Fplayers%2F{season}-{league_name_long}&div=div_stats_passing_types'\n",
    "                df_passing_types = pd.read_html(url_passing_types, header=1)[0]\n",
    "\n",
    "                ##### Goals and Shot Creation stats\n",
    "                print(f'Scraping Goals and Shot Creation stats...')\n",
    "                url_gca = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fgca%2Fplayers%2F{season}-{league_name_long}&div=div_stats_gca'\n",
    "                df_gca = pd.read_html(url_gca, header=1)[0]\n",
    "\n",
    "                ##### Defensive Actions stats\n",
    "                print(f'Scraping Defensive Actions stats...')\n",
    "                url_defense = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fdefense%2Fplayers%2F{season}-{league_name_long}&div=div_stats_defense'\n",
    "                df_defense = pd.read_html(url_defense, header=1)[0]\n",
    "\n",
    "                ##### Possession stats\n",
    "                print(f'Scraping Possession stats...')\n",
    "                url_possession = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fpossession%2Fplayers%2F{season}-{league_name_long}&div=div_stats_possession'\n",
    "                df_possession = pd.read_html(url_possession, header=1)[0]\n",
    "\n",
    "                ##### Playing Time stats\n",
    "                print(f'Scraping Playing Time stats...')\n",
    "                url_playing_time = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fplayingtime%2Fplayers%2F{season}-{league_name_long}&div=div_stats_playing_time'\n",
    "                df_playing_time = pd.read_html(url_playing_time, header=1)[0]\n",
    "\n",
    "                ##### Miscellaneous stats\n",
    "                print(f'Scraping Miscellaneous stats...')\n",
    "                url_misc = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=fb&url=%2Fen%2Fcomps%2F{league_name_short}%2F{season}%2Fmisc%2Fplayers%2F{season}-{league_name_long}&div=div_stats_misc'\n",
    "                df_misc = pd.read_html(url_misc, header=1)[0]\n",
    "\n",
    "                ##### Concatenate defined individual DataFrames\n",
    "                \n",
    "                ####### Define DataFrames to be concatenated side-by-side (not all of them)\n",
    "                lst_dfs = [df_std_stats, df_shooting, df_passing, df_passing_types, df_gca, df_defense, df_possession]\n",
    "\n",
    "                ###### Concatenate DataFrames side-by-side (indicated in list above)\n",
    "                df_all = pd.concat(lst_dfs, axis=1)\n",
    "\n",
    "                ###### Drop duplicate columns\n",
    "                df_all = df_all.loc[:,~df_all.columns.duplicated()]\n",
    "\n",
    "                ###### Drop duplicate rows\n",
    "                df_all = df_all.drop_duplicates()\n",
    "                \n",
    "                ##### Left join defined individual DataFrames\n",
    "                \n",
    "                ####### Define join conditions\n",
    "                conditions_join = ['Player', 'Nation', 'Pos', 'Squad', 'Comp']\n",
    "\n",
    "                ###### Left join Playing Time data\n",
    "                df_all = pd.merge(df_all, df_playing_time, left_on=conditions_join, right_on=conditions_join, how='left')\n",
    "\n",
    "                ###### Remove duplicate columns after join (contain '_y') and remove '_x' suffix from kept columns\n",
    "                df_all = df_all[df_all.columns.drop(list(df_all.filter(regex='_y')))]\n",
    "                df_all.columns = df_all.columns.str.replace('_x','')\n",
    "                \n",
    "                ###### Drop duplicate rows\n",
    "                df_all = df_all.drop_duplicates()\n",
    "\n",
    "                ###### Left join Misc data\n",
    "                df_all = pd.merge(df_all, df_misc, left_on=conditions_join, right_on=conditions_join, how='left')\n",
    "\n",
    "                ###### Remove duplicate columns after join (contain '_y') and remove '_x' suffix from kept columns\n",
    "                df_all = df_all[df_all.columns.drop(list(df_all.filter(regex='_y')))]\n",
    "                df_all.columns = df_all.columns.str.replace('_x','')\n",
    "                \n",
    "                ###### Drop duplicate rows\n",
    "                df_all = df_all.drop_duplicates()\n",
    "                \n",
    "                \n",
    "                ##### Engineer DataFrames\n",
    "                \n",
    "                ###### Take first two digits of age - fixes current season issue with extra values\n",
    "                df_all['Age'] = df_all['Age'].astype(str).str[:2]\n",
    "                \n",
    "                ###### Create columns for league code and season\n",
    "                df_all['League Name'] = league_name_long\n",
    "                df_all['League ID'] = league_name_short\n",
    "                df_all['Season'] = season              \n",
    "\n",
    "                ###### Drop duplicates\n",
    "                df_all = df_all.drop_duplicates()\n",
    "\n",
    "                \n",
    "                ##### Save DataFrame\n",
    "                df_all.to_csv(data_dir_fbref + f'/raw/outfield/{league_name_long}/{season}/fbref_outfield_player_stats_{league_name_long}_{season}_latest.csv', index=None, header=True, encoding='utf-8')        \n",
    "                \n",
    "                ##### Export a copy to the 'archive' subfolder, including the date\n",
    "                df_all.to_csv(data_dir_fbref + f'/raw/outfield/{league_name_long}/{season}/archive/fbref_outfield_player_stats_{league_name_long}_{season}_last_updated_{today}.csv', index=None, header=True, encoding='utf-8')        \n",
    "                \n",
    "                \n",
    "                ##### Print statement for league and season\n",
    "                print(f'All player stats data for the {league_name_long} league for {season} season scraped and saved.')\n",
    "             \n",
    "            \n",
    "            #### Load player stats data (if already saved)\n",
    "            else:\n",
    "\n",
    "                ##### Print statement\n",
    "                print(f'Player stats data for the {league_name_long} league for the {season} season already saved as a CSV file.')         \n",
    "\n",
    "                \n",
    "    ## End timer\n",
    "    toc = datetime.datetime.now()\n",
    "    \n",
    "    \n",
    "    ## Print time scraping ended\n",
    "    print(f'Scraping ended at: {toc}')\n",
    "\n",
    "    \n",
    "    ## Calculate time take\n",
    "    total_time = (toc-tic).total_seconds()\n",
    "    print(f'Time taken to scrape the player stats data for {len(league_names_long)} leagues for {len(seasons)} seasons is: {total_time/60:0.2f} minutes.')\n",
    "\n",
    "    \n",
    "    ## Unify individual CSV files as a single DataFrame\n",
    "    \n",
    "    ### Show files in directory\n",
    "    all_files = glob.glob(os.path.join(data_dir_fbref + f'/raw/outfield/*/*/fbref_outfield_player_stats_*_*_latest.csv'))\n",
    "    \n",
    "    ### Create an empty list of Players URLs\n",
    "    lst_player_stats_all = []\n",
    "\n",
    "    ### Loop through list of files and read into temporary DataFrames\n",
    "    for filename in all_files:\n",
    "        df_temp = pd.read_csv(filename, index_col=None, header=0)\n",
    "        lst_player_stats_all.append(df_temp)\n",
    "\n",
    "    ### Concatenate the files into a single DataFrame\n",
    "    df_fbref_player_stats_all = pd.concat(lst_player_stats_all, axis=0, ignore_index=True)\n",
    "    \n",
    "    ### Drop header row of each concatenated  DataFrame (contains 'Rk', 'Rk' column)\n",
    "    df_fbref_player_stats_all = df_fbref_player_stats_all[~df_fbref_player_stats_all['Rk'].str.contains('Rk')]\n",
    "    \n",
    "    ### Drop 'Rk' column\n",
    "    df_fbref_player_stats_all = df_fbref_player_stats_all.drop(['Rk'], axis=1)\n",
    "    \n",
    "    ### Reset index\n",
    "    #df_fbref_player_stats_all = df_fbref_player_stats_all.reset_index()\n",
    "    \n",
    "    ### Sort DataFrame\n",
    "    df_fbref_player_stats_all = df_fbref_player_stats_all.sort_values(['League Name', 'Season', 'Player'], ascending=[True, True, True])\n",
    "\n",
    "    \n",
    "    ## Export DataFrame\n",
    "    \n",
    "    ###\n",
    "    df_fbref_player_stats_all.to_csv(data_dir_fbref + f'/raw/outfield/fbref_outfield_player_stats_combined_latest.csv', index=None, header=True, encoding='utf-8')\n",
    "    \n",
    "    ### Save a copy to archive folder (dated)\n",
    "    df_fbref_player_stats_all.to_csv(data_dir_fbref + f'/raw/outfield/archive/fbref_outfield_player_stats_combined_last_updated_{today}.csv', index=None, header=True, encoding='utf-8')\n",
    "    \n",
    "    \n",
    "    ## Distinct number of players\n",
    "    total_players = df_fbref_player_stats_all['Player'].nunique()\n",
    "\n",
    "\n",
    "    ## Print statement\n",
    "    print(f'Player stats DataFrame contains {total_players} players.')\n",
    "    \n",
    "    \n",
    "    ## Return final list of Player URLs\n",
    "    return(df_fbref_player_stats_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c6c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a18e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac135d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
